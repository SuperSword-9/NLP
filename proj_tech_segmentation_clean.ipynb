{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-based Brain Tumour Segmentation Network\n",
    "## Import packages\n",
    "Please make sure you have all the required packages installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, concatenate, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import natsort\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import imageio\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import math\n",
    "import shutil\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise MRI Volume Slices and Segmentation Maps\n",
    "Each MRI image contains information about a three-dimensional (3D) volume of space. An MRI image is composed of a number of voxels, which is like pixels in 2D images. Here try to visualise the axial plane (usually has a higher resolution) of some of the volumes and the corresponding segmentation maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mri_3d_to_2d_z(input_main_folder, output_main_folder):\n",
    "    # 检查输出主文件夹是否存在，如果不存在则创建\n",
    "    if not os.path.exists(output_main_folder):\n",
    "        os.makedirs(output_main_folder)\n",
    "\n",
    "    # 遍历主输入文件夹中的所有子文件夹\n",
    "    for subfolder in os.listdir(input_main_folder):\n",
    "        subfolder_path = os.path.join(input_main_folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # 为当前子文件夹创建对应的输出子文件夹\n",
    "            output_subfolder = os.path.join(output_main_folder, subfolder)\n",
    "            if not os.path.exists(output_subfolder):\n",
    "                os.makedirs(output_subfolder)\n",
    "\n",
    "            # 遍历当前子文件夹中的所有文件\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                if filename.endswith('.nii') or filename.endswith('.nii.gz'):\n",
    "                    # 构建完整的文件路径\n",
    "                    input_file_path = os.path.join(subfolder_path, filename)\n",
    "                    # 读取3D MRI图像\n",
    "                    img = nib.load(input_file_path)\n",
    "                    # 获取图像数据\n",
    "                    img_data = img.get_fdata()\n",
    "\n",
    "                    # 提取文件名（去除扩展名）\n",
    "                    base_filename = os.path.splitext(os.path.splitext(filename)[0])[0]\n",
    "\n",
    "                    # 创建一个子文件夹来保存该3D图像的所有2D切片\n",
    "                    patient_folder = os.path.join(output_subfolder, base_filename)\n",
    "                    if not os.path.exists(patient_folder):\n",
    "                        os.makedirs(patient_folder)\n",
    "\n",
    "                    # 获取图像的尺寸\n",
    "                    _, _, z = img_data.shape\n",
    "\n",
    "                    # 提取轴向切片（Z方向）\n",
    "                    for slice_index in range(z):\n",
    "                        slice_data = img_data[:, :, slice_index]\n",
    "                        # 检查切片数据的最大值是否为零\n",
    "                        if slice_data.max() == 0:\n",
    "                            slice_data = np.zeros_like(slice_data, dtype=np.uint8)\n",
    "                        else:\n",
    "                            # 将数据转换为8位无符号整数类型\n",
    "                            slice_data = (slice_data / slice_data.max() * 255).astype(np.uint8)\n",
    "                        # 构建切片图像的文件名\n",
    "                        slice_filename = os.path.join(patient_folder, f'{base_filename}_axial_{slice_index}.png')\n",
    "                        # 保存切片图像\n",
    "                        imageio.imwrite(slice_filename, slice_data)\n",
    "\n",
    "#修改成你的路径\n",
    "input_main_folder = \"C://Users//zhangjw//Documents//WeChat Files//wxid_kmwrbkl7akml22//FileStorage//File//2025-02//tech_winter_school_2025//dataset_segmentation//train\"\n",
    "output_main_folder = \"C://Users//zhangjw//Documents//WeChat Files//wxid_kmwrbkl7akml22//FileStorage//File//2025-02//tech_winter_school_2025//dataset_segmentation//trainA\"\n",
    "mri_3d_to_2d_z(input_main_folder, output_main_folder)\n",
    "\n",
    "\n",
    "# 定义原始数据路径\n",
    "source_dir = r\"C:\\Users\\zhangjw\\Desktop\\testA\"\n",
    "photo_dir = r\"C:\\Users\\zhangjw\\Desktop\\photo1\"\n",
    "mask_dir = r\"C:\\Users\\zhangjw\\Desktop\\mask1\"\n",
    "\n",
    "# 创建目标文件夹\n",
    "os.makedirs(photo_dir, exist_ok=True)\n",
    "os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "# 计数器\n",
    "photo_index = 1\n",
    "mask_index = 1\n",
    "\n",
    "# 提取文件名中的最后一个数字（用于排序）\n",
    "def extract_number(filename):\n",
    "    numbers = re.findall(r'\\d+', filename)  # 找到所有数字\n",
    "    return int(numbers[-1]) if numbers else float('inf')  # 取最后一个数字\n",
    "\n",
    "# 遍历 trainA 目录中的所有编号文件夹（001-210）\n",
    "for folder_num in range(210, 252):  # 001-210\n",
    "    folder_name = f\"{folder_num:03d}\"  # 生成 3 位数格式的文件夹名\n",
    "    fla_path = os.path.join(source_dir, folder_name, f\"{folder_name}_fla\")\n",
    "    seg_path = os.path.join(source_dir, folder_name, f\"{folder_name}_seg\")\n",
    "\n",
    "    # 处理 fla 目录\n",
    "    if os.path.exists(fla_path):\n",
    "        files = sorted(os.listdir(fla_path), key=extract_number)  # 按最后的数字排序\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                src = os.path.join(fla_path, file)\n",
    "                dst = os.path.join(photo_dir, f\"{photo_index}.png\")  # 按顺序重命名\n",
    "                shutil.move(src, dst)\n",
    "                photo_index += 1\n",
    "\n",
    "    # 处理 seg 目录\n",
    "    if os.path.exists(seg_path):\n",
    "        files = sorted(os.listdir(seg_path), key=extract_number)  # 按最后的数字排序\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                src = os.path.join(seg_path, file)\n",
    "                dst = os.path.join(mask_dir, f\"{mask_index}.png\")  # 按顺序重命名\n",
    "                shutil.move(src, dst)\n",
    "                mask_index += 1\n",
    "\n",
    "print(f\"所有 fla 图片已移动到 {photo_dir}，共 {photo_index - 1} 张，文件名按 1.png, 2.png ... 命名。\")\n",
    "print(f\"所有 seg 图片已移动到 {mask_dir}，共 {mask_index - 1} 张，文件名按 1.png, 2.png ... 命名。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing (Optional)\n",
    "\n",
    "Images in the original dataset are usually in different sizes, so sometimes we need to resize and normalise (z-score is commonly used in preprocessing the MRI images) them to fit the CNN model. Depending on the images you choose to use for training your model, some other preprocessing methods. If preprocessing methods like cropping is applied, remember to convert the segmentation result back to its original size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-time data augmentation\n",
    "Generalizability is crucial to a deep learning model and it refers to the performance difference of a model when evaluated on the seen data (training data) versus the unseen data (testing data). Improving the generalizability of these models has always been a difficult challenge. \n",
    "\n",
    "**Data Augmentation** is an effective way of improving the generalizability, because the augmented data will represent a more comprehensive set of possible data samples and minimizing the distance between the training and validation/testing sets.\n",
    "\n",
    "There are many data augmentation methods you can choose in this projects including rotation, shifting, flipping, etc.\n",
    "\n",
    "You are encouraged to try different augmentation method to get the best segmentation result.\n",
    "\n",
    "\n",
    "## Get the data generator ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = r'C:\\Users\\21508\\PycharmProjects\\pythonProject8\\111\\predict'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 读取数据路径\n",
    "path_imgs = r\"C:\\Users\\21508\\PycharmProjects\\pythonProject8\\111\\photo\"\n",
    "path_masks = r\"C:\\Users\\21508\\PycharmProjects\\pythonProject8\\111\\mask\"\n",
    "\n",
    "# 获取所有图片\n",
    "imagesList = natsort.natsorted(os.listdir(path_imgs))\n",
    "maskList = natsort.natsorted(os.listdir(path_masks))\n",
    "\n",
    "# 确保 photo 和 mask 目录中的文件数量一致\n",
    "assert len(imagesList) == len(maskList), \"图片和掩码数量不匹配，请检查数据集！\"\n",
    "\n",
    "# 设定超参数\n",
    "img_row, img_col, img_chan = 240, 240, 1\n",
    "epochnum = 30 # 提高 epoch 以适应 EarlyStopping\n",
    "input_size = (img_row, img_col, img_chan)\n",
    "batch_size = 32\n",
    "\n",
    "# 数据集划分\n",
    "train_img_paths, test_img_paths, train_mask_paths, test_mask_paths = train_test_split(imagesList, maskList, test_size=0.2, random_state=42)\n",
    "val_img_paths, test_img_paths, val_mask_paths, test_mask_paths = train_test_split(test_img_paths, test_mask_paths, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"训练集大小: {len(train_img_paths)}, 验证集大小: {len(val_img_paths)}, 测试集大小: {len(test_img_paths)}\")\n",
    "\n",
    "# 数据增强\n",
    "import tensorflow.keras.preprocessing.image as img_prep\n",
    "\n",
    "def random_transform(img, mask):\n",
    "    datagen = img_prep.ImageDataGenerator(rotation_range=20, horizontal_flip=True)\n",
    "    params = datagen.get_random_transform(img.shape)\n",
    "    img = datagen.apply_transform(img, params)\n",
    "    mask = datagen.apply_transform(mask, params)\n",
    "    return img, mask\n",
    "\n",
    "# 数据生成器\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, img_paths, mask_paths, img_dir, mask_dir, batch_size, img_size):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.indexes = np.arange(len(self.img_paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.img_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_imgs = np.zeros((self.batch_size, *self.img_size, 1), dtype=np.float32)\n",
    "        batch_masks = np.zeros_like(batch_imgs)\n",
    "\n",
    "        for i, idx in enumerate(batch_indexes):\n",
    "            # 读取图像\n",
    "            img = load_img(os.path.join(self.img_dir, self.img_paths[idx]), target_size=self.img_size,\n",
    "                           color_mode=\"grayscale\")\n",
    "            img = img_to_array(img) / 255.0\n",
    "\n",
    "            mask = load_img(os.path.join(self.mask_dir, self.mask_paths[idx]), target_size=self.img_size,\n",
    "                            color_mode=\"grayscale\")\n",
    "            mask = img_to_array(mask) / 255.0\n",
    "\n",
    "            batch_imgs[i], batch_masks[i] = random_transform(img, mask)  # 应用数据增强\n",
    "\n",
    "        return batch_imgs, batch_masks\n",
    "\n",
    "# 创建数据生成器\n",
    "train_generator = DataGenerator(train_img_paths, train_mask_paths, path_imgs, path_masks, batch_size, (img_row, img_col))\n",
    "val_generator = DataGenerator(val_img_paths, val_mask_paths, path_imgs, path_masks, batch_size, (img_row, img_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a metric for the performance of the model\n",
    "Dice score is used here to evaluate the performance of your model.\n",
    "More details about the Dice score and other metrics can be found at \n",
    "https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2. Dice score can be also used as the loss function for training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsc(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dsc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own model here\n",
    "The U-Net (https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) structure is widely used for the medical image segmentation task. You can build your own model or modify the UNet by changing the hyperparameters for our task. If you choose to use Keras, more information about the Keras layers including Conv2D, MaxPooling and Dropout can be found at https://keras.io/api/layers/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(in_fmaps, num_fmaps):\n",
    "    conv1 = Conv2D(num_fmaps, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(in_fmaps)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.3)(conv1)\n",
    "    return Conv2D(num_fmaps, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(conv1)\n",
    "\n",
    "def Network():\n",
    "    input_layer = Input(shape=input_size)\n",
    "\n",
    "    conv1 = ConvBlock(input_layer, 32)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = ConvBlock(pool1, 32)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = ConvBlock(pool2, 64)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = ConvBlock(pool3, 64)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = ConvBlock(pool4, 128)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = ConvBlock(up6, 64)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = ConvBlock(up7, 64)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = ConvBlock(up8, 32)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = ConvBlock(up9, 32)\n",
    "\n",
    "    output_layer = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model here\n",
    "Once you defined the model and data generator, you can start training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss=dice_loss, metrics=[dsc])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True), ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)]\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=epochnum, verbose=1, callbacks=callbacks)\n",
    "print(\"训练完成 ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "Once your model is trained, remember to save it for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"version2.13.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model on the test set\n",
    "After your last Q&A session, you will be given the test set. Run your model on the test set to get the segmentation results and submit your results in a .zip file. If the MRI image is named '100_fla.nii.gz', save your segmentation result as '100_seg.nii.gz'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"version2.13.keras\", custom_objects={'dsc': dsc, 'dice_loss': dice_loss})\n",
    "\n",
    "# 设置测试图片目录和保存预测结果的目录\n",
    "test_img_dir = r\"C:\\Users\\21508\\PycharmProjects\\pythonProject8\\photo1\"  # 测试图片路径\n",
    "save_dir = r\"C:\\Users\\21508\\PycharmProjects\\pythonProject8\\test_predict\"  # 预测结果保存路径\n",
    "os.makedirs(save_dir, exist_ok=True)  # 创建保存目录\n",
    "\n",
    "# 获取所有测试图片\n",
    "test_images = natsort.natsorted(os.listdir(test_img_dir))\n",
    "\n",
    "# 对每张测试图片进行预测\n",
    "for img_name in test_images:\n",
    "    # 读取测试图片并预处理\n",
    "    img_path = os.path.join(test_img_dir, img_name)\n",
    "    img = load_img(img_path, target_size=(240,240), color_mode=\"grayscale\")\n",
    "    img = img_to_array(img) / 255.0  # 归一化\n",
    "    img = np.expand_dims(img, axis=0)  # 扩展维度\n",
    "\n",
    "    # 使用训练好的模型进行预测\n",
    "    pred = model.predict(img)\n",
    "    pred = np.squeeze(pred)  # 移除不必要的维度\n",
    "\n",
    "    # 保存预测结果\n",
    "    pred_img_path = os.path.join(save_dir, img_name)\n",
    "    plt.imsave(pred_img_path, pred, cmap='gray')\n",
    "\n",
    "    print(f\"预测完成：{img_name}\")\n",
    "\n",
    "print(\"所有图片预测完成 ✅\")\n",
    "\n",
    "# 设置图像目录和保存路径\n",
    "img_dir = r\"C:\\Users\\21508\\Desktop\\winter_school\\dataset_segmentation\\trainA\\001\\001_seg\"  # 图像文件夹\n",
    "save_dir = r\"C:\\Users\\21508\\PycharmProjects\\pythonProject8\\001seg_nii_files\"  # 3D图像保存路径\n",
    "sample_nii_path = r\"C:\\Users\\21508\\PycharmProjects\\pythonProject8\\211_fla.nii\" # 样本NIfTI文件路径\n",
    "\n",
    "# 获取样本NIfTI文件的尺寸\n",
    "sample_nii = nib.load(sample_nii_path)\n",
    "sample_data = sample_nii.get_fdata()\n",
    "\n",
    "# 获取样本的尺寸 (height, width, depth)\n",
    "sample_shape = sample_data.shape\n",
    "img_row, img_col, num_images_per_file = sample_shape[0], sample_shape[1], 155\n",
    "\n",
    "# 创建保存目录\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 获取所有图片并排序\n",
    "images_list = natsort.natsorted(os.listdir(img_dir))\n",
    "\n",
    "# 处理图像并保存为 3D NIfTI 文件\n",
    "for i in range(0, len(images_list), num_images_per_file):\n",
    "    # 选择当前批次的155张图像\n",
    "    batch_images = images_list[i:i + num_images_per_file]\n",
    "\n",
    "    # 加载并调整图像尺寸\n",
    "    img_stack = []\n",
    "    for img_name in batch_images:\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        img = load_img(img_path, target_size=(img_row, img_col), color_mode=\"grayscale\")\n",
    "        img = img_to_array(img) / 255.0  # 归一化\n",
    "        img_stack.append(img)\n",
    "\n",
    "    # 将图像堆叠成3D数组，并确保尺寸与样本相同\n",
    "    img_stack = np.stack(img_stack, axis=-1)\n",
    "    img_stack_resized = np.resize(img_stack, (img_row, img_col, num_images_per_file))\n",
    "\n",
    "    # 创建NIfTI图像\n",
    "    nifti_img = nib.Nifti1Image(img_stack_resized, affine=np.eye(4))  # 使用单位矩阵作为仿射矩阵\n",
    "\n",
    "    # 保存为nii.gz格式\n",
    "    nifti_filename = os.path.join(save_dir, f\"{str(i // num_images_per_file + 1).zfill(3)}.nii.gz\")\n",
    "    nib.save(nifti_img, nifti_filename)\n",
    "\n",
    "    print(f\"保存3D图像：{nifti_filename}\")\n",
    "\n",
    "print(\"所有文件转换完成 ✅\")\n",
    "\n",
    "# 设置目标目录\n",
    "root_dir = r\"C:\\Users\\21508\\PycharmProjects\\pythonProject8\\111\\nii_files\"  # 修改为实际路径\n",
    "\n",
    "# 获取所有文件夹\n",
    "folders = [f for f in os.listdir(root_dir)]\n",
    "\n",
    "# 目标名称范围\n",
    "start_num = 211\n",
    "end_num = 251\n",
    "def extract_number(filename):\n",
    "    numbers = re.findall(r'\\d+', filename)  # 找到所有数字\n",
    "    return int(numbers[-1]) if numbers else float('inf')  # 取最后一个数字\n",
    "# 确保文件夹数量匹配\n",
    "if len(folders) != (end_num - start_num + 1):\n",
    "    print(\"文件夹数量和目标命名数量不匹配，请检查！\")\n",
    "else:\n",
    "    for i, folder in enumerate(sorted(folders,key=extract_number)):  # 按字母顺序排序，避免随机顺序\n",
    "        new_name = f\"{(start_num + i):3d}_seg.nii.gz\"\n",
    "        old_path = os.path.join(root_dir, folder)\n",
    "        new_path = os.path.join(root_dir, new_name)\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"重命名: {folder} -> {new_name}\")\n",
    "\n",
    "    print(\"所有文件夹重命名完成！\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
